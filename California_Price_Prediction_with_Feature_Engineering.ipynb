{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2P0z0LwC1Xx",
        "outputId": "c2a5aefc-aca3-41e4-b4e0-5a5d02a28bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3784064344.py:31: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(os.path.join(data_dir, filename))\n",
            "/tmp/ipython-input-3784064344.py:74: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression R² (test):      0.3495\n",
            "Decision Tree R² (test):          0.9967\n",
            "Random Forest R² (test):          0.9712\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_dir = '/content/drive/My Drive/datasets/'\n",
        "\n",
        "file_list = [\n",
        "    \"CRMLSSold202501_filled.csv\",\n",
        "    \"CRMLSSold202502_filled.csv\",\n",
        "    \"CRMLSSold202503_filled.csv\",\n",
        "    \"CRMLSSold202504_filled.csv\",\n",
        "    \"CRMLSSold202505_filled.csv\",\n",
        "    \"CRMLSSold202506_filled.csv\",\n",
        "    \"CRMLSSold202507_filled.csv\",\n",
        "    \"CRMLSSold202508_filled-2.csv\",\n",
        "    \"CRMLSSold202509.csv\"\n",
        "]\n",
        "\n",
        "# Combine all months into one DF\n",
        "all_data = []\n",
        "for filename in file_list:\n",
        "    df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "    all_data.append(df)\n",
        "combined_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Preprocess\n",
        "df = combined_df[(combined_df['PropertyType'] == 'Residential') &\n",
        "                 (combined_df['PropertySubType'] == 'SingleFamilyResidence')]\n",
        "\n",
        "# Remove extreme outliers in ClosePrice using IQR\n",
        "q1 = df['ClosePrice'].quantile(0.25)\n",
        "q3 = df['ClosePrice'].quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "df = df[(df['ClosePrice'] >= lower_bound) & (df['ClosePrice'] <= upper_bound)]\n",
        "\n",
        "# Handle missing values\n",
        "for col in ['ViewYN', 'PoolPrivateYN', 'NewConstructionYN']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
        "        df[col] = df[col].fillna(0).astype(int)\n",
        "\n",
        "for col in ['LivingArea', 'BedroomsTotal', 'BathroomsTotalInteger', 'YearBuilt', 'LotSizeSquareFeet', 'Stories']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "if 'GarageSpaces' in df.columns:\n",
        "    df['GarageSpaces'] = df['GarageSpaces'].fillna(0)\n",
        "if 'PostalCode' in df.columns:\n",
        "    df = df.dropna(subset=['PostalCode'])\n",
        "\n",
        "# Feature Engineering\n",
        "df['PPSF'] = df['ClosePrice'] / df['LivingArea']\n",
        "df['BedBathRatio'] = df['BedroomsTotal'] / df['BathroomsTotalInteger'].replace(0, 1)\n",
        "df['BathBedRatio'] = df['BathroomsTotalInteger'] / df['BedroomsTotal'].replace(0, 1)\n",
        "df['PropertyAge'] = 2025 - df['YearBuilt']\n",
        "\n",
        "# Features\n",
        "feature_cols = [\n",
        "    'ViewYN', 'PoolPrivateYN', 'LivingArea', 'YearBuilt', 'BedroomsTotal', 'BathroomsTotalInteger',\n",
        "    'NewConstructionYN', 'GarageSpaces', 'LotSizeSquareFeet', 'Stories',\n",
        "    'PPSF', 'BedBathRatio', 'BathBedRatio', 'PropertyAge'\n",
        "]\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df = df.dropna(subset=feature_cols + ['ClosePrice'])\n",
        "\n",
        "# Split by month\n",
        "df['CloseDate'] = pd.to_datetime(df['CloseDate'])\n",
        "df['YearMonth'] = df['CloseDate'].dt.strftime('%Y-%m')\n",
        "\n",
        "# Training on months jan - aug, test on sep\n",
        "train_months = [\n",
        "    '2025-01', '2025-02', '2025-03', '2025-04',\n",
        "    '2025-05', '2025-06', '2025-07', '2025-08'\n",
        "]\n",
        "test_month = '2025-09'\n",
        "\n",
        "train_df = df[df['YearMonth'].isin(train_months)].copy()\n",
        "test_df = df[df['YearMonth'] == test_month].copy()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df['ClosePrice']\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df['ClosePrice']\n",
        "\n",
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "# Decision Tree with limited depth and min samples to hopefully reduce overfitting\n",
        "dt = DecisionTreeRegressor(random_state=42, max_depth=10, min_samples_split=20, min_samples_leaf=10)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "r2_dt = r2_score(y_test, y_pred_dt)\n",
        "\n",
        "# Random Forest with tuned hyperparameters\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=15,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    max_features='sqrt',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Linear Regression R² (test):      {r2_lr:.4f}\")\n",
        "print(f\"Decision Tree R² (test):          {r2_dt:.4f}\")\n",
        "print(f\"Random Forest R² (test):          {r2_rf:.4f}\")\n"
      ]
    }
  ]
}